{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asset Tracker Tool - Tracking serial numbers among multiple data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This tool compares data exports in CVS formate. Examples of datasets that can be compared include:\n",
    "\n",
    " - Installed Base\n",
    " - PageSmart (FMAudit data)\n",
    " - Project Rollout Schedule(s)\n",
    " - Monthly Billing File\n",
    " \n",
    "- Functions:\n",
    " - Phase 1: [current] Compare databases 1-to-1 to identify missing devices.\n",
    " - Phase 2: Data accuracy \n",
    " - Phase 3: Predictive corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Data Files and Global Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in source_file_names:  2\n",
      "Number of entries in source_file_names_large:  0\n",
      "Number of entries in cust_numbers:  4\n",
      "Number of entries in serial_number_name_variants:  5\n",
      "Number of entries in key_and_value_to_filter_out:  5\n",
      "Number of entries in potential_data_headers_keys:  16\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "import unicodecsv\n",
    "\n",
    "#####################################\n",
    "#               Formatting for comparison ease of read\n",
    "#####################################\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "#####################################\n",
    "#               Convert Excel to csv (.xlsx - data must be on Sheet1)\n",
    "#####################################\n",
    "import xlrd\n",
    "import csv\n",
    "\n",
    "def csv_from_excel(file1, new_file_name):\n",
    "    wb = xlrd.open_workbook(file1)\n",
    "    sh = wb.sheet_by_name('Sheet1')\n",
    "    your_csv_file = open(new_file_name, 'w')\n",
    "    wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "    for rownum in range(sh.nrows):\n",
    "        wr.writerow(sh.row_values(rownum))\n",
    "\n",
    "    your_csv_file.close()\n",
    "\n",
    "# runs the csv_from_excel function:\n",
    "#csv_from_excel('MGM IB.xlsx', \"MGM IB.csv\")\n",
    "\n",
    "#####################################\n",
    "#       WHICH FILES ARE WE LOOKING AT?\n",
    "#####################################\n",
    "'''\n",
    "    src files are standard exports, typically <1mb\n",
    "    src_large_n files are typically larger than a 1mb, up to 15mb\n",
    "    #IMPORTANT: Ensure gspmps.com instead of https://tabs.toshibameters.com to ensure youâ€™re looking at the most recent record when multiple FMAudit servers are installed for a single customer\n",
    "    #IMPORTANT: this is a single file for all ROS's \n",
    "'''\n",
    "src1 = 'MGM IB by 4 customer numbers 8.30.3019.csv'\n",
    "src2 = 'MGM FMA 8.15.2019 Device Change Worksheet.csv'\n",
    "src3 = ''\n",
    "src4 = ''\n",
    "# src3 = 'MGM Project ROS Summary.csv'\n",
    "# src4 = 'MGM Billing 8.27.2019.csv'\n",
    "src5 = ''\n",
    "src_large_1 = 'Full IB 8.21.2019 - serials only.csv'\n",
    "# src_large_2 = 'Full IB from 2016-2019 BRIEF.csv'\n",
    "src_large_2 = ''\n",
    "\n",
    "# source_file_names = [\n",
    "#     'MGM IB by 4 customer numbers 8.30.3019.csv',\n",
    "#     'MGM FMA 8.15.2019 Device Change Worksheet.csv',\n",
    "#     'MGM Project ROS Summary.csv',\n",
    "#     'EINVOICE-T0BUBPS-30-SEP-19.csv'\n",
    "#     ]\n",
    "\n",
    "# source_file_names_large = [\n",
    "#     'Full IB 8.21.2019 - serials only.csv',\n",
    "#     'Full IB from 2016-2019 BRIEF.csv'\n",
    "#     ]\n",
    "\n",
    "source_file_names = [\n",
    "    'AEG Project Implementation Roll Out Schedule.csv',\n",
    "    'Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv'\n",
    "    ]\n",
    "print(\"Number of entries in source_file_names: \", len(source_file_names))\n",
    "\n",
    "source_file_names_large = []\n",
    "print(\"Number of entries in source_file_names_large: \", len(source_file_names_large))\n",
    "\n",
    "\n",
    "\n",
    "#####################################\n",
    "#       MISC information\n",
    "#####################################\n",
    "#Customer Reference Number for Oracle Installed Base\n",
    "cust_numbers = list()\n",
    "cust_numbers = (\"T0BS49A\", \"T0BUQW1\", \"T0BV7VF\", \"T0BVMSY\")\n",
    "print(\"Number of entries in cust_numbers: \", len(cust_numbers))\n",
    "\n",
    "serial_number_name_variants = list()\n",
    "serial_number_name_variants = ['SERIAL_NUMBER','Serial Number','Toshiba Serial Number','SerialNbr', '\\ufeffSERIAL_NUMBER']\n",
    "print(\"Number of entries in serial_number_name_variants: \", len(serial_number_name_variants))\n",
    "\n",
    "key_and_value_to_filter_out = list()\n",
    "key_and_value_to_filter_out.append(('CUSTOMER_LOCATION_STATE','MD'))\n",
    "key_and_value_to_filter_out.append(('CUSTOMER_NAME', 'MGM STUDIOS'))\n",
    "key_and_value_to_filter_out.append(('CUSTOMER_NAME', 'MGM GALLERIES LLC'))\n",
    "key_and_value_to_filter_out.append(('CUSTOMER_NAME', 'MGM LIQUOR WAREHOUSE'))\n",
    "key_and_value_to_filter_out.append(('CUSTOMER_NAME', 'MGM MORTGAGE'))\n",
    "\n",
    "print(\"Number of entries in key_and_value_to_filter_out: \", len(key_and_value_to_filter_out))\n",
    "\n",
    "#What are some headings you'd like to see if we find missing assets?\n",
    "potential_data_headers_keys = list()\n",
    "potential_data_headers_keys = ['serial_number', \\\n",
    "                               'ACTION', 'Completed Install Date', 'Last Report Date' , \\\n",
    "                               'Primary', 'STATUS for Delivery / Installation', \\\n",
    "                               'Location Name', 'Completed Install Date' \\\n",
    "                               'Ship To / Company Name','Address1', 'Model', \\\n",
    "                               'Ship-To Name', 'Ship To Address1', 'Install Date', 'Status'\\\n",
    "                               'INSTALL_DATE','CUSTOMER_NAME','CUSTOMER_LOCATION_ADDRESS_1']     \n",
    "print(\"Number of entries in potential_data_headers_keys: \", len(potential_data_headers_keys))\n",
    "\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mSample pulled from MGM IB by 4 customer numbers 8.30.3019.csv\u001b[0m, entry from 0th list entry: \n",
      "OrderedDict([('\\ufeffPRODUCT_NUMBER', '63451262'), ('INSTALL_DATE', '4/1/2019'), ('GOLD_FLAG', 'Y'), ('CUSTOMER_REFERENCE', 'T0BS49A'), ('CUSTOMER_NAME', 'MGM RESORTS INTERNATIONAL'), ('SRC_PARTY_SITE_NUMBER', '2601839'), ('CUSTOMER_LOCATION_ADDRESS_1', '71 E HARMON AVE'), ('CUSTOMER_LOCATION_ADDRESS_2', ''), ('CUSTOMER_LOCATION_CITY', 'LAS VEGAS'), ('CUSTOMER_LOCATION_STATE', 'NV'), ('CUSTOMER_LOCATION_ZIP', '89109-4539'), ('SRV_DEALER_REFERENCE', '00740600'), ('SRV_DEALER_NAME', 'TOSHIBA BUSINESS SOLUTIONS AZ-CO'), ('SRV_DEALER_LOCATION_ADDRESS_1', 'C/O MGM RESORTS'), ('SRV_DEALER_LOCATION_ADDRESS_2', '5014 BOND STREET'), ('SRV_DEALER_LOCATION_CITY', 'LAS VEGAS'), ('SRV_DEALER_LOCATION_STATE', 'NV'), ('SRV_DEALER_LOCATION_ZIP', '89118-1575'), ('ORIG_DEALER_REFERENCE', '00743600'), ('ORIG_DEALER_NAME', 'TABS NO COMP'), ('MODEL_NUMBER', 'ESTUDIO2802AF'), ('SERIAL_NUMBER', 'SCUBJ51625'), ('EXPIRED_FLAG', 'N'), ('ORDER_TYPE', 'LSE'), ('ORDER_NUMBER', ''), ('ORDER_DATE', ''), ('SHIPPED_DATE', ''), ('INVOICE_NO', ''), ('AUTO_CREATE_FSM', 'Processed'), ('CA_DATE', '30-APR-19'), ('SYSTEM_NAME', 'SCUBJ51625'), ('SRC_INSTANCE_ID', '63451262'), ('PURCHASE_ORDER', ''), ('ASSET_TAG_NUMBER', 'SCUBJ51625'), ('AGREEMENT', '')])\n",
      "\u001b[4mSample pulled from MGM FMA 8.15.2019 Device Change Worksheet.csv\u001b[0m, entry from 0th list entry: \n",
      "OrderedDict([('\\ufeffDevice ID', '1884272'), ('Device Name', 'HL-3170CDW series'), ('Model', 'Brother HL-3170CDW'), ('Serial Number', 'U63478D3J153685'), ('IP Address', '10.6.64.30'), ('Last Report Date ', '8/13/2019'), ('Managed', 'Unmanaged'), ('Ship To / Company Name', ''), ('Address1', ''), ('Address 2', ''), ('Attention', ''), ('City', ''), ('State', ''), ('Zip', ''), ('Location', ''), ('Asset Number', ''), ('Cost Center', ''), ('EUConfirmation Email', ''), ('Program Type', ''), ('Black Part', ''), ('Cyan Part', ''), ('Magenta Part', ''), ('Yellow Part', '')])\n",
      "\u001b[4mSample pulled from Full IB 8.21.2019 - serials only.csv\u001b[0m, entry from 0th list entry: \n",
      "OrderedDict([('\\ufeffSERIAL_NUMBER', 'SCLJ585945')])\n",
      "----------------------------------------------------------\n",
      "\n",
      "Importing 1: AEG Project Implementation Roll Out Schedule.csv as new list: data_set_1\n",
      "\u001b[4mSample pulled from AEG Project Implementation Roll Out Schedule.csv\u001b[0m, entry from 0th list entry: \n",
      "OrderedDict([('\\ufeffUID', '66'), ('Phase', 'Phase 1'), ('Group', 'Group 2'), ('Priority', ''), ('Location Name', 'Regency SF'), ('Street Address', '1290 SUTTER ST'), ('City', 'SAN FRANCISCO'), ('State', 'CA'), ('Zip', '94109-5564'), ('Service Provider', 'TBS CA/NV'), ('Ship To Location', 'Union City CA'), ('Current Device', 'C3350'), ('Current Device Serial Number', 'A4Y4011009337'), ('ACTION', 'CONVERT TRIAL'), ('Toshiba Replacement Device', 'ESTUDIO3515AC'), ('Replacement Toshiba Device Configuration', 'MR4000B, KD1059B, GD1370N, \\nPWRFLTR-D113Z6T'), ('Price Agreement Name', 'TABS_AEG MFP CONTRACT TRAUNCH 1 TRIAL 133145'), ('Toshiba Serial Number', 'SCNCJ36223'), ('Trial?', 'Y'), ('Fax?', ''), ('Toshiba MAC Address (if Dynamic)', ''), ('Toshiba Device Dimensions', '48 x 26 x 24'), ('Proposed Power Required', 'NEMA 5-15 (115V 15A)'), ('Toshiba Power Needed', '120 V, 12 A'), ('Current KM Power Used', '120 V, 12 A'), ('Power Change Proposed (Y/N)', 'Y'), ('Power Notes', ''), ('Print Environment', ''), ('Space Issue?', ''), ('Site Contact Name', ''), ('Site Contact Phone', ''), ('Site Contact Email', ''), ('IT Contact Name', ''), ('IT Contact Phone', ''), ('IT Group Name', 'Digital Services'), ('IP Address', '10.8.185.100'), ('Fax Number', ''), ('Network', ''), ('Gateway', '10.8.185.5'), ('Subnet', '255.255.255.0'), ('Printer Name', 'SVC_PRN_REG@aegworldwide.com'), ('DNS Server(s)', 'DNS Primary:  10.4.209.24\\nDNS Secondary:  10.8.49.21'), ('SMTP Login Name, Email From-Addr, From Name', 'SVC_PRN_REG@aegworldwide.com'), ('SMTP Email Setting', 'smtp.office365.com'), ('Network Config (Static/Dynamic)', ''), ('Network Jack Needed? (Y/N)', ''), ('Clone File Name', 'AEG_7516AC_MSTR_Clone_V2_190628.enc'), ('Oracle Invoice Number', ''), ('Oracle Sales Number', '5736756'), ('Order Date', ''), ('Order Notes', ''), ('Ship By Date', 'TRIAL'), ('Equipment Receipt Date', ''), ('Scheduled Delivery Date', '04/19/19'), ('Special Delivery / Installation Notes', ''), ('Scheduled Installation Week Of', 'Week of 07/15/19'), ('Scheduled Installation Date', '07/19/19'), ('Scheduled Training Date', '07/19/19'), ('Equipment Installed?', 'YES'), ('Installation Issue Category', 'COMPLETE'), ('Issue Notes', ''), ('Completed Install Date', '04/19/19'), ('Received CA (Date)', '04/19/19'), ('Equipment Training Date Completed', '04/19/19'), ('Training Notes', ''), ('Change Request', ''), ('Change Request Scheduled Install Date (Fax, etc.)', ''), ('Change Request Installed (Fax Card)?', ''), ('AEG Add/New Fund Approval', ''), ('AEG / Konica Current Term Date', '08/18/19'), ('AEG / Konica Ship Date', '07/24/19'), ('AEG / Konica Return By Date', '08/02/19'), ('Date Last Updated', '07/26/19 9:48 AM'), ('Modified By', 'kathi.pang@tabs.toshiba.com'), ('Device Connection Type', 'Networked'), ('Traunch #', 'Traunch 1'), ('Finance Group', 'AEG Presents'), ('Billing Address', 'PO Box 9004, Lawrence, KS 66044'), ('Billing Email', 'AEG_Presents_AP_LA@scanningamerica.com'), ('Lease Term', '63 Months'), ('Ref Install Date', 'CONVERT TRIAL'), ('REPLACE Count', '0'), ('TRIAL CONVERSION COUNT', '1'), ('COMPLETE Count', '1')])\n",
      "\n",
      "Importing 2: Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv as new list: data_set_2\n",
      "\u001b[4mSample pulled from Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv\u001b[0m, entry from 0th list entry: \n",
      "OrderedDict([('\\ufeffCustomer PO#', '9694692-001'), ('Invoice#', '5058357'), ('Parent Invoice Number', '388002'), ('Invoice Date', '16-SEP-19'), ('Cont#', 'US0022149MA'), ('Status', 'ACTIVE'), ('Ship-To Name', 'ANSCHUTZ ENTERTAINMENT GROUP INC'), ('Ship To Address1', '865 S FIGUEROA ST'), ('Ship To Address2', 'AEG 1st FL BEHIND CUBE 104 13'), ('Ship To City', 'LOS ANGELES'), ('Ship To State', 'CA'), ('Ship To Zip Code', '90017-2543'), ('Model', 'ESTUDIO7516ACT'), ('Serial Number', 'SC1EJ15306'), ('Base Date Billed From', '01-AUG-19'), ('Base Date Billed To', '31-AUG-19'), ('Usage', '0'), ('Base Charge', '169.54'), ('Total Charge', '169.54'), ('Tax', '0'), ('Amount Due', ' $169.54 '), ('Install Date', '12-JUL-19')])\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#       IMPORT SCRIPTS FOR EACH THAT EXPORTS SAMPLE OF SERIAL NUMBER\n",
    "#####################################\n",
    "\n",
    "\n",
    "def import_cvs_into_list(source_cvs):\n",
    "    \"\"\"\n",
    "        Imports CSV into list\n",
    "        Args:\n",
    "            source_cvs\n",
    "        Returns:\n",
    "            data_list\n",
    "    \"\"\"\n",
    "    #creates a list where each row is list entry. Each list entry is a collection of Dict's\n",
    "    data_list = []\n",
    "    with open(source_cvs, 'rb') as f:\n",
    "        reader = unicodecsv.DictReader(f)\n",
    "        for row in reader:\n",
    "            data_list.append(row)\n",
    "    #List value of row:\n",
    "    print(color.UNDERLINE + \"Sample pulled from \" + source_cvs + color.END + \", entry from 0th list entry: \")\n",
    "    print(data_list[0])\n",
    "    return data_list\n",
    "\n",
    "ib_devices = list()\n",
    "pagesmart_devices = list()\n",
    "ros_devices = list()\n",
    "ib_full_devices = list()\n",
    "billing_devices = list()\n",
    "ib_full_brief_devices = list()\n",
    "\n",
    "if src1:\n",
    "    ib_devices = import_cvs_into_list(src1)\n",
    "if src2:\n",
    "    pagesmart_devices = import_cvs_into_list(src2)\n",
    "if src3:\n",
    "    ros_devices = import_cvs_into_list(src3)\n",
    "if src_large_1:\n",
    "    ib_full_devices_serials = import_cvs_into_list(src_large_1)\n",
    "if src4:\n",
    "    billing_devices = import_cvs_into_list(src4)\n",
    "if src5:\n",
    "    misc_devices = import_cvs_into_list(src5)\n",
    "if src_large_2:\n",
    "    ib_full_brief_devices = import_cvs_into_list(src_large_2)\n",
    "\n",
    "#####################################\n",
    "#       IMPORT SCRIPTS FOR EACH THAT EXPORTS SAMPLE OF SERIAL NUMBER [VERION 2.0]\n",
    "#####################################\n",
    "print(\"----------------------------------------------------------\")\n",
    "source_file_lists=list()\n",
    "source_file_lists_large=list()\n",
    "\n",
    "for num, file_name in enumerate(source_file_names, start=1):\n",
    "    print(\"\\nImporting {}: {} as new list: data_set_{}\".format(num, file_name, num))\n",
    "    locals()[\"data_set_\" + str(num)] = import_cvs_into_list(file_name)\n",
    "    source_file_lists.append(locals()[\"data_set_\" + str(num)])\n",
    "\n",
    "for num, file_name in enumerate(source_file_names_large, start=1):\n",
    "    print(\"\\nImporting: {} as new list: data_set_large_{}\".format(file_name, num))\n",
    "    locals()[\"data_set_large_\" + str(num)] = import_cvs_into_list(file_name)\n",
    "    source_file_lists_large.append(locals()[\"data_set_large_\" + str(num)])\n",
    "\n",
    "# print(len(source_file_lists[0]))\n",
    "# print(source_file_lists[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harmonize data keys e.g. Serial Number columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCUBJ51625\n",
      "U63478D3J153685\n",
      "I did the thing!\n",
      "----------------------------------------------------------\n",
      "SCNCJ36223\n",
      "SC1EJ15306\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#               Harmonize Keys      #\n",
    "#####################################\n",
    "\n",
    "def harmonize_serial_number_key(list_a):\n",
    "    \"\"\"\n",
    "    Since Serial Number is primary key, they key name sshould be the same among all tables\n",
    "    ArgS:\n",
    "        list_a\n",
    "    Returns:\n",
    "        none\n",
    "    \"\"\"\n",
    "    for row in list_a:\n",
    "        if ('serial_number') in row:\n",
    "            continue\n",
    "        for sn_variant in serial_number_name_variants:\n",
    "            if sn_variant in row:\n",
    "                row['serial_number'] = row[sn_variant]\n",
    "                del row[sn_variant]\n",
    "        if ('serial_number') not in row:\n",
    "            print(\"Issue: Did not find serial number key.\")\n",
    "\n",
    "            \n",
    "if src1:\n",
    "    harmonize_serial_number_key(ib_devices)\n",
    "    print(ib_devices[0]['serial_number'])\n",
    "    \n",
    "if src2:\n",
    "    harmonize_serial_number_key(pagesmart_devices)\n",
    "    print(pagesmart_devices[0]['serial_number'])\n",
    "\n",
    "if src3:\n",
    "    harmonize_serial_number_key(ros_devices)\n",
    "    print(ros_devices[0]['serial_number'])\n",
    "\n",
    "#NOTE: src_large_1 is already a list of just serial numbers to reduce resource drain on computer\n",
    "# if src_large_1:\n",
    "#     harmonize_serial_number_key(ib_full_devices_serials)\n",
    "#     print(ib_full_devices_serials[0]['serial_number'])    \n",
    "    \n",
    "if src4:\n",
    "    harmonize_serial_number_key(billing_devices)\n",
    "    print(billing_devices[0]['serial_number'])\n",
    "\n",
    "if src_large_2:\n",
    "    harmonize_serial_number_key(ib_full_brief_devices)\n",
    "    print(ib_full_brief_devices[0]['serial_number'])\n",
    "\n",
    "print(\"I did the thing!\")\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "for data_set in source_file_lists:\n",
    "    harmonize_serial_number_key(data_set)\n",
    "    print(data_set[0]['serial_number'])\n",
    "\n",
    "for data_set in source_file_lists_large:\n",
    "    harmonize_serial_number_key(data_set)\n",
    "    print(data_set[0]['serial_number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Data Types - FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#     Add data types other than string, IB portion and functions\n",
    "#####################################\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Takes a date as a string, and returns a Python datetime object. \n",
    "# If there is no date given, returns None\n",
    "def parse_date(date):\n",
    "    if date == '' or date == None:\n",
    "        return None\n",
    "    else:\n",
    "        return dt.strptime(date, '%m/%d/%Y')\n",
    "        #return dt.strptime(date, '%m/%d/%Y %H:%M:%S')\n",
    "        \n",
    "    \n",
    "# Takes a string which is either an empty string or represents an integer,\n",
    "# and returns an int or None.\n",
    "def parse_maybe_int(i):\n",
    "    if i == '':\n",
    "        return None\n",
    "    else:\n",
    "        return int(i)\n",
    "    \n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n",
      "----------------------------------------------------------\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "if src1:    \n",
    "    # Clean up the data types an INSTALL BASE table\n",
    "    for ib_device in ib_devices:\n",
    "        ib_device['INSTALL_DATE'] = parse_date(ib_device['INSTALL_DATE'])\n",
    "        #ib_device['days_to_cancel'] = parse_maybe_int(enrollment['days_to_cancel'])\n",
    "        ib_device['GOLD_FLAG'] = ib_device['GOLD_FLAG'] == 'True'\n",
    "\n",
    "print(\"I did the thing!\")\n",
    "    \n",
    "print(\"----------------------------------------------------------\")\n",
    "for data_set in source_file_lists:\n",
    "    if 'INSTALL_DATE' in data_set[0].keys():\n",
    "        for data_entry in data_set:\n",
    "            data_entry['INSTALL_DATE'] = parse_date(data_entry['INSTALL_DATE'])\n",
    "    if 'GOLD_FLAG' in data_set[0].keys():\n",
    "        for data_entry in data_set:\n",
    "            data_entry['GOLD_FLAG'] = data_entry['GOLD_FLAG'] == 'True'\n",
    "    if 'Last Report Date' in data_set[0].keys():\n",
    "        for data_entry in data_set:\n",
    "            data_entry['Last Report Date'] = parse_date(data_entry['Last Report Date'])\n",
    "\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find/List Duplicate Serial Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGM IB by 4 customer numbers 8.30.3019.csv\n",
      "Total devices checked: 1898\n",
      "Total unique devices: 1897\n",
      "Total blanks: 0\n",
      "Total duplicates devices: 1\n",
      "\u001b[1mDuplicate records found. Please investigate then delete applicable record(s).\u001b[0m\n",
      "{'JPCCL9N0FJ'} \n",
      "\n",
      "MGM FMA 8.15.2019 Device Change Worksheet.csv\n",
      "Total devices checked: 4059\n",
      "Total unique devices: 3494\n",
      "Total blanks: 565\n",
      "Total duplicates devices: 565\n",
      "set() \n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------------------------\n",
      "AEG Project Implementation Roll Out Schedule.csv\n",
      "Total devices checked: 77\n",
      "Total unique devices: 50\n",
      "Total blanks: 27\n",
      "Total duplicates devices: 27\n",
      "set() \n",
      "\n",
      "Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv\n",
      "Total devices checked: 163\n",
      "Total unique devices: 81\n",
      "Total blanks: 1\n",
      "Total duplicates devices: 82\n",
      "\u001b[1mDuplicate records found. Please investigate then delete applicable record(s).\u001b[0m\n",
      "{'S75289200F3ZHX', 'S75289200F3ZH9', 'S75289200F3ZHT', 'SCNEJ51688', 'SCNEJ51680', 'SC1EJ15590', 'SCNEJ51781', 'SCNEJ51941', 'SC1EJ15722', 'SC1EJ15718', 'SCNEJ51780', 'SCNEJ51761', 'SC1CJ14378', 'S75289200F3ZGY', 'SCNEJ51672', 'SCNEJ51667', 'SCNEJ51783', 'SCNEJ51919', 'SC1EJ15586', 'SCNEJ51682', 'SCNEJ52055', 'SC1EJ15594', 'SC1EJ15587', 'SCNEJ51766', 'SC1EJ15330', 'SCNEJ51767', 'SCNEJ51867', 'SCNEJ51668', 'SCNEJ51677', 'SCNEJ51665', 'S75289200F3ZH0', 'SC1EJ15589', 'SC1EJ15331', 'SC1EJ15306', 'SCNEJ51768', 'SCNEJ51994', 'SCNEJ51779', 'SCNEJ51676', 'SC1EJ15709', 'SC1EJ15294', 'SC1EJ15715', 'SC1EJ15339', 'SC1EJ15717', 'SC1EJ15714', 'SC1EJ15580', 'SC1EJ15581', 'SC1EJ15713', 'SCNEJ52022', 'SCNEJ51933', 'SCNEJ52053', 'SC1EJ15726', 'SCNEJ50964', 'SCNEJ51669', 'SCNEJ51660', 'SCNEJ51760', 'SCNEJ51944', 'SC1EJ15588', 'SCNEJ50910', 'SCNEJ50943', 'SC1EJ15712', 'SCNEJ51670', 'SCNEJ51666', 'SC1EJ15593', 'SC1CJ14373', 'SCNEJ50970', 'SCNIH43154', 'SC1EJ15603', 'SCNEJ51771', 'SCNEJ51945', 'SC1EJ15584', 'SC1EJ15585', 'SC1EJ15592', 'SCNEJ50935', 'SCNEJ52041', 'SCNEJ51931', 'S75289200F3ZHN', 'SCNEJ52046', 'SCNEJ51772', 'SCNEJ51775', 'SC1EJ15579', 'SC1DJ15001'} \n",
      "\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#                 Find unique and non-blank, post duplicates\n",
    "#####################################\n",
    "\n",
    "## Find the total number of rows and the number of unique students (account keys)\n",
    "## in each table.\n",
    "\n",
    "def find_unique_and_none_blank(input_list):\n",
    "    unique_values = set()\n",
    "    duplicate_values = set()\n",
    "    blank_counter = 0\n",
    "    for row in input_list:\n",
    "        if not row['serial_number']:\n",
    "            blank_counter += 1\n",
    "        elif row['serial_number'] not in unique_values:\n",
    "            unique_values.add(row['serial_number'])\n",
    "        elif row['serial_number'] is not None:\n",
    "            duplicate_values.add(row['serial_number'])\n",
    "            \n",
    "    \n",
    "    print('Total devices checked: ' +  str(len(input_list)))\n",
    "    print('Total unique devices: ' + str(len(unique_values)))\n",
    "    print('Total blanks: ' + str(blank_counter))\n",
    "    \n",
    "    if (len(input_list)!=len(unique_values)):\n",
    "        print(\"Total duplicates devices: \" + str(len(input_list)-len(unique_values)))\n",
    "        if(len(duplicate_values) > 1 or duplicate_values):\n",
    "            print(color.BOLD + \"Duplicate records found. Please investigate then delete applicable record(s).\" \\\n",
    "                  + color.END)\n",
    "    return duplicate_values\n",
    "    \n",
    "#####################################\n",
    "#               List orig vs duplicates count\n",
    "#####################################\n",
    "\n",
    "print (src1), print(find_unique_and_none_blank(ib_devices), \"\\n\") if src1 else None\n",
    "print (src2), print(find_unique_and_none_blank(pagesmart_devices), \"\\n\") if src2 else None\n",
    "print (src3), print(find_unique_and_none_blank(ros_devices), \"\\n\") if src3 else None\n",
    "print (src4), print(find_unique_and_none_blank(billing_devices), \"\\n\") if src4 else None\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "for list_name, data_set in zip(source_file_names,source_file_lists):\n",
    "    print (list_name)\n",
    "    print (find_unique_and_none_blank(data_set), \"\\n\")\n",
    "\n",
    "    \n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for \"Silly S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSCUBJ51625\n",
      "SCUBJ51625\n",
      "I did the thing!\n",
      "----------------------------------------------------------\n",
      "SSCNCJ36223\n",
      "SCNCJ36223\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#    Compare serial numbers that may have \"Silly S\"\n",
    "#####################################\n",
    "#Some serials have the \"Silly S\" at the beginning.  Check values with added 'S' and removed first character to check against.\n",
    "def check_serial_silly_s(input_serial, check_against_list):\n",
    "    if (input_serial in check_against_list):\n",
    "        return input_serial\n",
    "    elif ((\"S\"+input_serial) in check_against_list):\n",
    "#         print('S added to beginning of Serial for ' + str(input_serial))\n",
    "        return (\"S\"+input_serial)\n",
    "    elif ((input_serial[1:]) in check_against_list):\n",
    "#         print('First Character removed to beginning of Serial for ' + str(input_serial))\n",
    "        return (input_serial[1:])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#test above function\n",
    "if src1:\n",
    "    print(check_serial_silly_s(\"S\"+ib_devices[0]['serial_number'],\"S\" + ib_devices[0]['serial_number']))\n",
    "    print(check_serial_silly_s(\"S\"+ib_devices[0]['serial_number'],(ib_devices[0]['serial_number'])))\n",
    "print(\"I did the thing!\")\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "#test above function\n",
    "print(check_serial_silly_s(\"S\"+source_file_lists[0][0]['serial_number'],\"S\" + source_file_lists[0][0]['serial_number']))\n",
    "print(check_serial_silly_s(\"S\"+source_file_lists[0][0]['serial_number'],(source_file_lists[0][0]['serial_number'])))\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create unique serials lists (removing duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[4mib_devices total rows: 1898\u001b[0m\n",
      "Total unique devices after check: 1897\n",
      "This function returned a list that removed the following number of duplicates: 1\n",
      "\n",
      "\u001b[4mpagesmart_devices total rows: 4059\u001b[0m\n",
      "Total unique devices after check: 3495\n",
      "This function returned a list that removed the following number of duplicates: 564\n",
      "\n",
      "----------------------------------------------------------\n",
      "['AEG Project Implementation Roll Out Schedule.csv', 'Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv']\n",
      "\n",
      "Creating new list of unique serial numbers from file: AEG Project Implementation Roll Out Schedule.csv. \n",
      "Named: data_set_unique_serials_1\n",
      "Total unique devices after check: 51\n",
      "This function returned a list that removed the following number of duplicates: 26\n",
      "\n",
      "\n",
      "Creating new list of unique serial numbers from file: Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv. \n",
      "Named: data_set_unique_serials_2\n",
      "Total unique devices after check: 82\n",
      "This function returned a list that removed the following number of duplicates: 81\n",
      "\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "#     Create unique value list (remove duplicates)\n",
    "#####################################\n",
    "\n",
    "## Find any one student ib_devices where the student is missing from the daily engagement table.\n",
    "## Output that enrollment.\n",
    "\n",
    "def find_unique_and_return_list(input_list):\n",
    "    unique_values = set()\n",
    "    for row in input_list:\n",
    "        if row['serial_number'] not in unique_values:\n",
    "            unique_values.add(row['serial_number'])\n",
    "    print('Total unique devices after check: ' + str(len(unique_values)))\n",
    "    if (len(input_list)!=len(unique_values)):\n",
    "        print(\"This function returned a list that removed the following number of duplicates: \" \\\n",
    "              + str(len(input_list)-len(unique_values)) + '\\n')\n",
    "    return unique_values\n",
    "\n",
    "if src1: \n",
    "    print(color.UNDERLINE +'ib_devices total rows: ' + str(len(ib_devices)) + color.END)\n",
    "    ib_devices_unique_device_serials = find_unique_and_return_list(ib_devices)\n",
    "\n",
    "if src2:\n",
    "    print(color.UNDERLINE +'pagesmart_devices total rows: ' + str(len(pagesmart_devices)) + color.END)\n",
    "    pagesmart_devices_unique_device_serials = find_unique_and_return_list(pagesmart_devices)\n",
    "\n",
    "if src3:\n",
    "    print(color.UNDERLINE +'ros_devices total rows: ' + str(len(ros_devices)) + color.END)\n",
    "    ros_devices_unique_device_serials = find_unique_and_return_list(ros_devices)\n",
    "\n",
    "if src4:\n",
    "    print(color.UNDERLINE +'billing_devices total rows: ' + str(len(billing_devices)) + color.END)\n",
    "    billing_devices_unique_device_serials = find_unique_and_return_list(billing_devices)\n",
    "    \n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "# for list_name, data_set in zip(source_file_names,source_file_lists):\n",
    "#     print (color.UNDERLINE + list_name + color.END )\n",
    "#     print (find_unique_and_none_blank(data_set), \"\\n\")\n",
    "source_file_unique_serials = list()\n",
    "source_file_unique_serials_large = list()\n",
    "\n",
    "print(source_file_names)\n",
    "\n",
    "for num, data_set in enumerate(source_file_lists, start=1):\n",
    "    print(\"\\nCreating new list of unique serial numbers from file: {}. \\nNamed: data_set_unique_serials_{}\".format(source_file_names[num-1], num))\n",
    "    locals()[\"data_set_unique_serials_\" + str(num)] = find_unique_and_return_list(data_set)\n",
    "    source_file_unique_serials.append(locals()[\"data_set_unique_serials_\" + str(num)])\n",
    "    \n",
    "for num, data_set in enumerate(source_file_lists_large, start=1):\n",
    "    print(\"\\nCreating new list of unique serial numbers from file: {}. \\nNamed: data_set_unique_serials_large_{}\".format(source_file_names_large[num-1], num))\n",
    "    locals()[\"data_set_unique_serials_large_\" + str(num)] = find_unique_and_return_list(data_set)\n",
    "    source_file_unique_serials_large.append(locals()[\"data_set_unique_serials_large_\" + str(num)])\n",
    "    \n",
    "print(\"I did the thing!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Filter for Search Part 1: FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "def filter_out(filter_keys_values_list, unique_serials_list, orig_data_set):\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "        Removes entries based on filter\n",
    "        Args: \n",
    "            list_a \n",
    "            key\n",
    "            key 2 (if applicable)\n",
    "        Returns:\n",
    "            filtered_list\n",
    "    #####################################\n",
    "    \"\"\"\n",
    "    filtered_list = list()\n",
    "    removed_list = list()\n",
    "    print('\\nBefore: quantity of lists\\' entries: ' + str(len(unique_serials_list)))\n",
    "\n",
    "    # create data list using unique serial numbers:\n",
    "    full_data_unique = list()\n",
    "    for unique_entry in unique_serials_list:\n",
    "        # find orig data entry\n",
    "        for orig_entry in orig_data_set:\n",
    "            if (unique_entry == orig_entry['serial_number']):\n",
    "                full_data_unique.append(orig_entry)\n",
    "                break\n",
    "    \n",
    "    filtered_list =  full_data_unique\n",
    "    \n",
    "    for filter_item in filter_keys_values_list:\n",
    "        key = filter_item[0]\n",
    "        value = filter_item[1]\n",
    "        print(\"Removing key/value: \", key, value)\n",
    "        if key in full_data_unique[0].keys():\n",
    "            for entry in full_data_unique:\n",
    "                if entry[key] == value:\n",
    "                    #print(\"Removing: \", entry['serial_number'])\n",
    "                    removed_list.append(entry)\n",
    "                    filtered_list.remove(entry)\n",
    "                    \n",
    "    if (removed_list):\n",
    "        print(\"Number of entries removed: \" + color.RED + str(len(removed_list)) + color.END + \" out of a total \" + str(len(unique_serials_list)))\n",
    "        \n",
    "    print('After: quantity of lists\\' entries: ' + str(len(full_data_unique)))\n",
    "    return filtered_list\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Filter for Search Part 2: CRITERIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of ib_data_filterd:  5\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#What's in IB that should not be in PS/ROS?\n",
    "ib_data_to_filter = list()\n",
    "ib_data_to_filter.append(('CUSTOMER_LOCATION_STATE','MD'))\n",
    "ib_data_to_filter.append(('CUSTOMER_NAME', 'MGM STUDIOS'))\n",
    "ib_data_to_filter.append(('CUSTOMER_NAME', 'MGM GALLERIES LLC'))\n",
    "ib_data_to_filter.append(('CUSTOMER_NAME', 'MGM LIQUOR WAREHOUSE'))\n",
    "ib_data_to_filter.append(('CUSTOMER_NAME', 'MGM MORTGAGE'))\n",
    "\n",
    "print(\"Length of ib_data_filterd: \", len(ib_data_to_filter))\n",
    "ps_data_to_filter_from_ib = list()\n",
    "\n",
    "if src1 and src3: \n",
    "    #What's in PS that would not be in IB?\n",
    "    ps_data_to_filter_from_ib = list()\n",
    "    print(\"Length of ps_data_filterd_from_ib: \", len(ps_data_to_filter_from_ib))\n",
    "\n",
    "if src2 and src3: \n",
    "    #What's in PS that won't be in ROS?\n",
    "    ps_data_to_filter_from_ros = list()\n",
    "    print(\"Length of ps_data_filterd_from_ros: \", len(ps_data_to_filter_from_ros))\n",
    "\n",
    "if src3 and src2: \n",
    "    #Note: All ROS (installed) should be in PS - No filters suggested\n",
    "    ros_data_to_filter_from_ps = list()\n",
    "    print(\"Length of ros_data_to_filter_from_ps: \", len(ros_data_to_filter_from_ps))\n",
    "\n",
    "if src1 and src3: \n",
    "    #Note: All ROS (installed) should be in IB - No filters suggested\n",
    "    ros_data_to_filter_from_ib = list()\n",
    "    print(\"Length of ros_data_to_filter_from_ib: \", len(ros_data_to_filter_from_ib))\n",
    "\n",
    "if src4: \n",
    "    #Note: All BILLING (installed) should be in IB - No filters suggested\n",
    "    billing_data_to_filter = list()\n",
    "    print(\"Length of ros_data_to_filter_from_ib: \", len(billing_data_to_filter))\n",
    "\n",
    "print(\"I did the thing!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Filter for Search Part 3: PERFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before: quantity of lists' entries: 1897\n",
      "Removing key/value:  CUSTOMER_LOCATION_STATE MD\n",
      "Removing key/value:  CUSTOMER_NAME MGM STUDIOS\n",
      "Removing key/value:  CUSTOMER_NAME MGM GALLERIES LLC\n",
      "Removing key/value:  CUSTOMER_NAME MGM LIQUOR WAREHOUSE\n",
      "Removing key/value:  CUSTOMER_NAME MGM MORTGAGE\n",
      "Number of entries removed: \u001b[91m232\u001b[0m out of a total 1897\n",
      "After: quantity of lists' entries: 1665\n",
      "\n",
      "Before: quantity of lists' entries: 3495\n",
      "After: quantity of lists' entries: 3495\n",
      "----------------------------------------------------------\n",
      "\n",
      "Creating new list of filtered devices: AEG Project Implementation Roll Out Schedule.csv. \n",
      "Named: data_set_unique_filtered_data_1\n",
      "\n",
      "Before: quantity of lists' entries: 51\n",
      "Removing key/value:  CUSTOMER_LOCATION_STATE MD\n",
      "Removing key/value:  CUSTOMER_NAME MGM STUDIOS\n",
      "Removing key/value:  CUSTOMER_NAME MGM GALLERIES LLC\n",
      "Removing key/value:  CUSTOMER_NAME MGM LIQUOR WAREHOUSE\n",
      "Removing key/value:  CUSTOMER_NAME MGM MORTGAGE\n",
      "After: quantity of lists' entries: 51\n",
      "\n",
      "Creating new list of filtered devices: Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv. \n",
      "Named: data_set_unique_filtered_data_2\n",
      "\n",
      "Before: quantity of lists' entries: 82\n",
      "Removing key/value:  CUSTOMER_LOCATION_STATE MD\n",
      "Removing key/value:  CUSTOMER_NAME MGM STUDIOS\n",
      "Removing key/value:  CUSTOMER_NAME MGM GALLERIES LLC\n",
      "Removing key/value:  CUSTOMER_NAME MGM LIQUOR WAREHOUSE\n",
      "Removing key/value:  CUSTOMER_NAME MGM MORTGAGE\n",
      "After: quantity of lists' entries: 82\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#ros_found_in_ib = check_and_list_missing_serials_in_lists(ros_devices_unique_device_serials, ib_devices_unique_device_serials)\n",
    "\n",
    "\n",
    "#INSTALL BASE FILTERS\n",
    "if src1:\n",
    "    ib_data_filtered = filter_out(ib_data_to_filter, ib_devices_unique_device_serials, ib_devices)\n",
    "\n",
    "if src2 and src1:\n",
    "    ps_data_filtered_for_ib = filter_out(ps_data_to_filter_from_ib, pagesmart_devices_unique_device_serials, pagesmart_devices)\n",
    "# if src2 and src3:\n",
    "#     ps_data_filtered_for_ros = filter_out(ps_data_to_filter_from_ros, pagesmart_devices_unique_device_serials, pagesmart_devices)\n",
    "    \n",
    "# if src3 and src2: \n",
    "#     ros_data_filtered_for_ps = filter_out(ros_data_to_filter_from_ps, ros_devices_unique_device_serials, ros_devices)\n",
    "# if src3 and src1:\n",
    "#     ros_data_filtered_for_ib = filter_out(ros_data_to_filter_from_ib, ros_devices_unique_device_serials, ros_devices)\n",
    "    \n",
    "# if src4 and src1: \n",
    "#     billing_data_filtered_for_ib = filter_out(billing_data_to_filter, billing_devices_unique_device_serials, billing_devices)\n",
    "\n",
    "print(\"----------------------------------------------------------\")\n",
    "key_and_value_to_filter_out\n",
    "\n",
    "# for list_name, data_set in zip(source_file_names,source_file_lists):\n",
    "#     print (color.UNDERLINE + list_name + color.END )\n",
    "#     print (find_unique_and_none_blank(data_set), \"\\n\")\n",
    "source_file_unique_filtered_data = list()\n",
    "source_file_unique_filtered_data_large = list()\n",
    "\n",
    "for num, data_set in enumerate(source_file_lists, start=1):\n",
    "    print(\"\\nCreating new list of filtered devices: {}. \\nNamed: data_set_unique_filtered_data_{}\".format(source_file_names[num-1], num))\n",
    "    locals()[\"data_set_unique_filtered_data_\" + str(num)] = filter_out(key_and_value_to_filter_out, source_file_unique_serials[num-1], data_set)\n",
    "    source_file_unique_filtered_data.append(locals()[\"data_set_unique_filtered_data_\" + str(num)])\n",
    "    \n",
    "# for num, data_set in enumerate(source_file_lists_large, start=1):\n",
    "#     print(\"\\nCreating new list of unique serial numbers from file: {}. \\nNamed: data_set_unique_serials_large_{}\".format(source_file_names_large[num-1], num))\n",
    "#     locals()[\"data_set_unique_serials_large_\" + str(num)] = find_unique_and_return_list(data_set)\n",
    "#     source_file_unique_serials_large.append(locals()[\"data_set_unique_serials_large_\" + str(num)])\n",
    "\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Find/List Missing Serials From Each DB FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from prettytable import PrettyTable\n",
    "from datetime import datetime\n",
    "\n",
    "#comparison function between two lists \n",
    "def check_and_list_missing_serials_in_lists(list_a, list_b):\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "        Takes in two lists (each list is a list of dicts for a devices e.g. serial_number key to asdf1234 value)\n",
    "            and compares them to each other finding matches and \"not_found\" based on serial_number.\n",
    "        Args: \n",
    "            list_a - entries to be check, return values are based on these entries\n",
    "            list_b - entires to check against\n",
    "        Returns:\n",
    "            found_matches - a list of entries from list_a that were found in list_b based on serial_number\n",
    "            not_found - a list of entries from list_a that were NOT found in list_b based on serial_number\n",
    "    #####################################\n",
    "    \"\"\"\n",
    "    \n",
    "    #Print output \n",
    "    print(color.UNDERLINE +'\\nComparison stats:\\n' + color.END + \\\n",
    "     \" â€¢ \" + 'Quantity of primary lists\\' entries: ' + str(len(list_a)))\n",
    "\n",
    "    found_matches = list()\n",
    "    not_found = list()\n",
    "    for device in list_a:\n",
    "        device_serial = device['serial_number'] \n",
    "        if check_serial_silly_s(device_serial, list_b):\n",
    "            found_matches.append(device)\n",
    "            continue\n",
    "        else:\n",
    "            not_found.append(device)\n",
    "            \n",
    "    #Print output         \n",
    "    print(\" â€¢ \" + 'Matches found: ' + str(len(found_matches)))\n",
    "\n",
    "    if (not_found):\n",
    "        output_sample_records(not_found)\n",
    "\n",
    "    return found_matches, not_found\n",
    "\n",
    "print(\"I did the thing!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Find/List Missing Serials From Each OUTPUT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "def output_sample_records(list_a):\n",
    "    rows = list()\n",
    "    headers = list()\n",
    "    #Print output         \n",
    "    print (\" â€¢ \" + 'Total Missing: ' + str(len(list_a)) + \" \\n\" \\\n",
    "    + color.BOLD + \"Please investigate then add applicable record(s). Some Key fields: \\n\" + color.END)\n",
    "\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    \n",
    "    for potential_key in potential_data_headers_keys:\n",
    "        if potential_key in list_a[0].keys():\n",
    "            headers.append(potential_key)\n",
    "\n",
    "    #Check if ROS headers exist and then output\n",
    "    if (headers):\n",
    "        for entry in list_a:\n",
    "            #temp new row variable to add to rows as single line\n",
    "            new_row = list()\n",
    "            for found_potential_header in headers:\n",
    "                new_row.append(entry[found_potential_header])\n",
    "            rows.append(new_row)\n",
    "                \n",
    "    #else (no header matches)\n",
    "    else:\n",
    "        headers = 'serial_number'\n",
    "        for entry in list_a:\n",
    "            rows.append(entry['serial_number'])\n",
    "\n",
    "    print(tabulate(rows, headers))\n",
    "\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records Part 1 - Find/List Missing Serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "This section will compare each list against each other and provide missing device information.\n",
      "There are 2 lists.\n",
      "\u001b[4m\n",
      "List comparison:\u001b[0m If any devices are listed below, they are in... \n",
      " â€¢ \u001b[92mAEG Project Implementation Roll Out Schedule.csv\u001b[0m but are missing from... \n",
      " â€¢ \u001b[1m\u001b[91mMissing from Copy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv\u001b[0m\n",
      "Coding troubleshooting (if needed) note: Iterator index: 0. \n",
      "compare_to_index: 1.\n",
      "\u001b[4m\n",
      "Comparison stats:\n",
      "\u001b[0m â€¢ Quantity of primary lists' entries: 51\n",
      " â€¢ Matches found: 45\n",
      " â€¢ Total Missing: 6 \n",
      "\u001b[1mPlease investigate then add applicable record(s). Some Key fields: \n",
      "\u001b[0m\n",
      "----------------------------------------------------------\n",
      "serial_number    ACTION         Completed Install Date    Location Name\n",
      "---------------  -------------  ------------------------  -----------------\n",
      "\n",
      "SCNCJ36223       CONVERT TRIAL  04/19/19                  Regency SF\n",
      "SCNEJ51926       REPLACE        07/17/19                  AEG Legal Hallway\n",
      "SC1EJ15667       REPLACE        07/22/19                  LA Kings- TSC\n",
      "SC1FJ16221       REPLACE        07/19/19                  AEG LIVE DENVER\n",
      "SC1FJ16226       REPLACE        07/19/19                  AEG LIVE DENVER\n",
      "\n",
      "I did the thing!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    TO DO\\n    Reverse order check e.g. 2 against 1\\n    Dyanmic or earlier selected additional data fields e.g. \"Install Status\" vs \"Status of delivery/install\"\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################\n",
    "#                 LIST MISSING SERIAL NUMBERS\n",
    "#####################################\n",
    "# if src3 and src1:\n",
    "#     print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "#          \" â€¢ \" + \"\" + color.GREEN + src3 + color.END + \" but are... \\n\" + \\\n",
    "#          \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + src1 + color.END)\n",
    "#     ros_found_in_ib = check_and_list_missing_serials_in_lists(ib_data_filtered, ps_data_filtered_for_ib)\n",
    "    \n",
    "# if src2 and src1:\n",
    "#     print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "#          \" â€¢ \" + \"\" + color.GREEN + src2 + color.END + \" but are... \\n\" + \\\n",
    "#          \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + src1 + color.END)\n",
    "#     ps_found_in_ib = check_and_list_missing_serials_in_lists(ib_data_filtered, pagesmart_devices_unique_device_serials)\n",
    "    \n",
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "#TO DO: itereate among filtered lists to check against unique serials lists\n",
    "\n",
    "total_lists = len(source_file_lists)\n",
    "\n",
    "print(\"This section will compare each list against each other and provide missing device information.\\nThere are {} lists.\".format(total_lists))  \n",
    "\n",
    "if total_lists > 1:\n",
    "    for num, data_set in enumerate(source_file_unique_filtered_data, start=0):\n",
    "        compare_to_index = num+1\n",
    "        while compare_to_index < total_lists:\n",
    "            print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "            \" â€¢ \" + \"\" + color.GREEN + source_file_names[num] + color.END + \" but are missing from... \\n\" + \\\n",
    "            \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + source_file_names[compare_to_index] + color.END)\n",
    "            print(\"Coding troubleshooting (if needed) note: Iterator index: {}. \\ncompare_to_index: {}.\".format(num, \\\n",
    "                                                                        compare_to_index))    \n",
    "            locals()[\"data_set_matches_\" + str(num)] = check_and_list_missing_serials_in_lists(source_file_unique_filtered_data[num], \\\n",
    "                                                                                               source_file_unique_serials[compare_to_index])\n",
    "            #source_file_unique_filtered_data.append(locals()[\"data_set_unique_filtered_data_\" + str(num)])\n",
    "            compare_to_index = compare_to_index+1\n",
    "\n",
    "print(\"\\nI did the thing!\")\n",
    "\n",
    "\n",
    "'''\n",
    "    TO DO\n",
    "    Reverse order check e.g. 2 against 1\n",
    "    Dyanmic or earlier selected additional data fields e.g. \"Install Status\" vs \"Status of delivery/install\"\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records Part 2 - Reverse Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "This section will compare each list against each other and provide missing device information.\n",
      "There are 2 lists.\n",
      "\u001b[4m\n",
      "List comparison:\u001b[0m If any devices are listed below, they are in... \n",
      " â€¢ \u001b[92mCopy of AUGUST 2019 WELLS FARGO - ANSCHUTZ ENTERTAINMENT INVOICE.csv\u001b[0m but are missing from... \n",
      " â€¢ \u001b[1m\u001b[91mMissing from AEG Project Implementation Roll Out Schedule.csv\u001b[0m\n",
      "Coding troubleshooting (if needed) note: Iterator index: 1. \n",
      "compare_to_index: 0.\n",
      "\u001b[4m\n",
      "Comparison stats:\n",
      "\u001b[0m â€¢ Quantity of primary lists' entries: 82\n",
      " â€¢ Matches found: 45\n",
      " â€¢ Total Missing: 37 \n",
      "\u001b[1mPlease investigate then add applicable record(s). Some Key fields: \n",
      "\u001b[0m\n",
      "----------------------------------------------------------\n",
      "serial_number    Model           Ship-To Name                      Ship To Address1           Install Date\n",
      "---------------  --------------  --------------------------------  -------------------------  --------------\n",
      "\n",
      "S75289200F3ZHX   ESTUDIO389CS    ANSCHUTZ ENTERTAINMENT GROUP INC  425 W 11TH ST              22-JUL-19\n",
      "S75289200F3ZH9   ESTUDIO389CS    ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         17-JUL-19\n",
      "S75289200F3ZHT   ESTUDIO389CS    ANSCHUTZ ENTERTAINMENT GROUP INC  18400 AVALON BLVD          22-JUL-19\n",
      "SCNEJ51780       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         18-JUL-19\n",
      "SCNEJ51761       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  18400 AVALON BLVD          10-JUL-19\n",
      "SC1CJ14378       ESTUDIO6516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  865 S FIGUEROA ST          13-JUN-19\n",
      "S75289200F3ZGY   ESTUDIO389CS    ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         23-JUL-19\n",
      "SCNEJ51682       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         15-JUL-19\n",
      "SCNEJ52055       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         12-JUL-19\n",
      "SCNEJ51766       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  777 CHICK HEARN CT         16-JUL-19\n",
      "SCNEJ51767       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  18400 AVALON BLVD          10-JUL-19\n",
      "SCNEJ51867       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  425 W 11TH ST              11-JUL-19\n",
      "SCNEJ51668       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  18400 AVALON BLVD          10-JUL-19\n",
      "SCNEJ51677       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  865 S FIGUEROA ST          09-JUL-19\n",
      "S75289200F3ZH0   ESTUDIO389CS    ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         17-JUL-19\n",
      "SCNEJ51676       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         15-JUL-19\n",
      "SC1EJ15709       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         15-JUL-19\n",
      "SC1EJ15715       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         18-JUL-19\n",
      "SC1EJ15717       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         12-JUL-19\n",
      "SC1EJ15714       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         18-JUL-19\n",
      "SC1EJ15580       ESTUDIO5516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  425 W 11TH ST              11-JUL-19\n",
      "SC1EJ15581       ESTUDIO5516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  777 CHICK HEARN CT         16-JUL-19\n",
      "SCNEJ51933       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  865 S FIGUEROA ST          09-JUL-19\n",
      "SCNEJ52053       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  865 S FIGUEROA ST STE 800  09-JUL-19\n",
      "SC1EJ15726       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         12-JUL-19\n",
      "SCNEJ51669       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  777 CHICK HEARN CT         16-JUL-19\n",
      "SCNEJ51944       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         23-JUL-19\n",
      "SC1EJ15712       ESTUDIO7516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         12-JUL-19\n",
      "SCNEJ51666       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         17-JUL-19\n",
      "SC1CJ14373       ESTUDIO6516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  800 W OLYMPIC BLVD         17-JUL-19\n",
      "SCNIH43154       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         15-JUL-19\n",
      "SCNEJ51771       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  425 W 11TH ST              11-JUL-19\n",
      "SCNEJ51945       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  777 CHICK HEARN CT         16-JUL-19\n",
      "SCNEJ52041       ESTUDIO4515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         15-JUL-19\n",
      "SCNEJ51775       ESTUDIO3515AC   ANSCHUTZ ENTERTAINMENT GROUP INC  18400 AVALON BLVD          10-JUL-19\n",
      "SC1DJ15001       ESTUDIO6516ACT  ANSCHUTZ ENTERTAINMENT GROUP INC  1111 S FIGUEROA ST         12-JUL-19\n",
      "\n",
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "\n",
    "#TO DO: itereate among filtered lists to check against unique serials lists\n",
    "\n",
    "total_lists = len(source_file_lists)\n",
    "\n",
    "print(\"This section will compare each list against each other and provide missing device information.\\nThere are {} lists.\".format(total_lists))  \n",
    "\n",
    "if total_lists > 1:\n",
    "    for num, data_set in reversed(list(enumerate(source_file_unique_filtered_data, start=total_lists-2))):\n",
    "        compare_to_index = num-1\n",
    "        while compare_to_index >= 0:\n",
    "            print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "            \" â€¢ \" + \"\" + color.GREEN + source_file_names[num] + color.END + \" but are missing from... \\n\" + \\\n",
    "            \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + source_file_names[compare_to_index] + color.END)\n",
    "            print(\"Coding troubleshooting (if needed) note: Iterator index: {}. \\ncompare_to_index: {}.\".format(num, \\\n",
    "                                                                        compare_to_index))    \n",
    "            locals()[\"data_set_matches_\" + str(num)] = check_and_list_missing_serials_in_lists(source_file_unique_filtered_data[num], \\\n",
    "                                                                                               source_file_unique_serials[compare_to_index])\n",
    "            #source_file_unique_filtered_data.append(locals()[\"data_set_unique_filtered_data_\" + str(num)])\n",
    "            compare_to_index = compare_to_index-1\n",
    "\n",
    "print(\"\\nI did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Find/List Missing Serials PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if src1 and src3:\n",
    "#     print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "#          \" â€¢ \" + \"\" + color.GREEN + src1 + color.END + \" but are... \\n\" + \\\n",
    "#          \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + src3 + color.END)\n",
    "\n",
    "#     ib_found_in_ps = check_and_list_missing_serials_in_lists(ib_data_filtered, ros_devices_unique_device_serials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Records - Find/List Missing Serials PART 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if src3 and src4:\n",
    "#     print(color.UNDERLINE +'\\nList comparison:' + color.END + ' If any devices are listed below, they are in... \\n'  + \\\n",
    "#          \" â€¢ \" + \"\" + color.GREEN + src3 + color.END + \" but are... \\n\" + \\\n",
    "#          \" â€¢ \" +  color.BOLD + color.RED + \"Missing from \" + src4 + color.END)\n",
    "# #\n",
    "#     ros_found_in_billing = check_and_list_missing_serials_in_lists(ros_data_filtered_for_ps, billing_devices_unique_device_serials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deeper dive into IB FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I did the thing!\n"
     ]
    }
   ],
   "source": [
    "#comparison function between two lists \n",
    "def found_and_missing_devices(list_a, list_b):\n",
    "    \"\"\"\n",
    "    #####################################\n",
    "        Takes in two lists (each list is a list of dicts for a devices e.g. serial_number key to asdf1234 value)\n",
    "            and compares them to each other finding matches and \"not_found\" based on serial_number.\n",
    "        Args: \n",
    "            list_a - entries to be check, return values are based on these entries\n",
    "            list_b - entires to check against\n",
    "        Returns:\n",
    "            found_matches - a list of entries from list_a that were found in list_b based on serial_number\n",
    "            not_found - a list of entries from list_a that were NOT found in list_b based on serial_number\n",
    "    #####################################\n",
    "    \"\"\"\n",
    "    #Print output \n",
    "    print(color.UNDERLINE +'\\nComparison stats:\\n' + color.END + \\\n",
    "     \" â€¢ \" + 'Quantity of primary lists\\' entries: ' + str(len(list_a)))\n",
    "\n",
    "    found_matches = list()\n",
    "    not_found = list()\n",
    "    for device in list_a:\n",
    "        device_serial = device['serial_number'] \n",
    "        if check_serial_silly_s(device_serial, list_b):\n",
    "            found_matches.append()\n",
    "            continue\n",
    "        else:\n",
    "            not_found.append(device)\n",
    "            \n",
    "    #Print output         \n",
    "    print(\" â€¢ \" + 'Matches found: ' + str(len(found_matches)))\n",
    "\n",
    "    if (not_found):\n",
    "        output_sample_records(not_found)\n",
    "\n",
    "    return found_matches, not_found\n",
    "\n",
    "print(\"I did the thing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IB DEEPER DIVE - Import full list of IB serials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "['SCLJ585945']\n"
     ]
    }
   ],
   "source": [
    "## Deeper dive with full IB Serial list using NumPy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "if src_large_1 and src1: \n",
    "    full_ib_serials = np.array(pd.read_csv(src_large_1))\n",
    "    print (full_ib_serials.dtype)\n",
    "    print(full_ib_serials[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IB DEEPER DIVE - Output list of serials found in project but not found in IB Customer nor IB Full.  TOTALLY MISSING FROM IB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ros_found_in_ib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-f2608f4b06df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msrc_large_1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0msrc1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"There were the following number NOT found in IB: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mros_found_in_ib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdevices_missing_vs_found_in_full_ib\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_and_list_missing_serials_in_lists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mros_found_in_ib\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_ib_serials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ros_found_in_ib' is not defined"
     ]
    }
   ],
   "source": [
    "if src_large_1 and src1: \n",
    "    print(\"There were the following number NOT found in IB: \", len(ros_found_in_ib[1]))\n",
    "    devices_missing_vs_found_in_full_ib = check_and_list_missing_serials_in_lists(ros_found_in_ib[1],full_ib_serials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## IB DEEPER DIVE - Record accuracy issue - Found in full IB data but NOT customer-number IB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Please investigate then correct issues for these record(s). Some Key fields: \\n\")\n",
    "\n",
    "# variables: devices_missing_vs_found_in_full_ib [0=found in previous comparison, 1=not found]\n",
    "# We want to list the IB details about the ones found. Total list found in devices_missing_vs_found_in_full_ib[0]\n",
    "if src_large_1 and src1: \n",
    "    if (devices_missing_vs_found_in_full_ib[0]):\n",
    "        output_sample_records(devices_missing_vs_found_in_full_ib[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## IB DEEPER DIVE - Import full IB BRIEF list to get more IB information (resource heavy operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deeper dive with full IB Serial list using NumPy\n",
    "if src_large_2 and src1:\n",
    "    full_ib_brief_serials = np.array(pd.read_csv(src_large_2))\n",
    "    print (full_ib_brief_serials.dtype)\n",
    "    print(full_ib_brief_serials[0])\n",
    "    print ('I did the thing!)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## IB DEEPER DIVE: Output IB data found in project but not customer-IB. i.e. Same as above but with data from IB instead of project. (resource heavy operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Please investigate then correct issues for these record(s). Some Key fields: \\n\")\n",
    "if src_large_2 and src1: \n",
    "    if (devices_missing_vs_found_in_full_ib[0]):\n",
    "        rows = list()\n",
    "        #Print output         \n",
    "        print (\" â€¢ \" + 'Total Found with issue: ' + str(len(devices_missing_vs_found_in_full_ib[0])) + \" \\n\" \\\n",
    "        + color.BOLD + \"Please investigate then correct applicable record(s). Some Key fields: \\n\" + color.END)\n",
    "        print(\"These may not have known customer nubmers: T0BS49A, T0BUQW1, T0BV7VF, T0BVMSY\")\n",
    "        print(\"Ken's Observation on customer numbers: 506502, 507534, 640983\")\n",
    "    \n",
    "    #Check if IB headers exist and then output\n",
    "    headers = ('serial_number','INSTALL_DATE','CUSTOMER_REFERENCE','CUSTOMER_NAME', \"CUSTOMER_LOCATION_ADDRESS_1\")\n",
    "    for entry in devices_missing_vs_found_in_full_ib[0]:\n",
    "        for ib_entry in full_ib_brief_serials:\n",
    "            if entry['serial_number'] == ib_entry[5]:\n",
    "                rows.append([ib_entry[5], ib_entry[0], ib_entry[1],\n",
    "                             ib_entry[2], ib_entry[3]])\n",
    "                break\n",
    "\n",
    "    print(tabulate(rows, headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Devices Found vs. Not-Found between Various Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"Project Devices Installed: \" + str(len(ros_devices_unique_device_serials)))\n",
    "\n",
    "print(\"\\n â€¢ \" + \"Project Devices found in the Billing file: \" + str(len(ros_found_in_billing[0])) + \\\n",
    "\"\\n â€¢ \" + \"And those not found: \" +  str(len(ros_found_in_billing[1]))) if src4 and src3 else None\n",
    "\n",
    "print( \"\\n â€¢ \" + \"Project Devices found in PageSmart: \" + str(len(ros_found_in_ps[0])) + \\\n",
    "\"\\n â€¢ \" + \"And those not found: \" +  str(len(ros_found_in_ps[1])) ) if src2 and src3 else None\n",
    "\n",
    "\n",
    "print( \"\\n â€¢ \" + \"Project Devices found in IB (Oracle Installed Base): \" + str(len(ros_found_in_ib[0])) + \\\n",
    "\"\\n â€¢ \" + \"And those not found: \" +  str(len(ros_found_in_ib[1])) ) if src1 and src3 else None\n",
    "\n",
    "print(\"\\n   â€¢ \" + \"Of which were found in IB with data issue: \" + str(len(devices_missing_vs_found_in_full_ib[0])) + \\\n",
    "\"\\n   â€¢ \" + \"And those not found at all: \" +  str(len(devices_missing_vs_found_in_full_ib[1])) ) if src_large_1 and src1 else None\n",
    "\n",
    "\n",
    "print(\"\\nInstalled Base (Oracle) Devices pulled using customer numbers: \", cust_numbers )\n",
    "\n",
    "print(\"Installed Base (Oracle) Devices: \" + str(len(ib_devices_unique_device_serials)) + \\\n",
    "    \"\\n â€¢ \" + \"IB Devices found in PageSmart: \" + str(len(ib_found_in_ps[0])) + \\\n",
    "    \"\\n â€¢ \" + \"And those not found: \" +  str(len(ib_found_in_ps[1])) ) if src1 and src2 else None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Export Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# with open(\"exported_spreadsheet.csv\", 'w', newline='') as myfile:\n",
    "#      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "#      wr.writerow(ros_found_in_billing[1])\n",
    "    \n",
    "# np.savetxt(\"file_name.csv\", ros_found_in_billing[1], delimiter=\",\", fmt='%s', header=header)\n",
    "\n",
    "# print(ros_found_in_billing[1][0].keys())\n",
    "\n",
    "# toCSV = [ros_found_in_billing[1]]\n",
    "# keys = ros_found_in_billing[1][0].keys()\n",
    "# with open('people.csv', 'wb') as output_file:\n",
    "#     dict_writer = newline.DictWriter(output_file, keys)\n",
    "#     dict_writer.writeheader()\n",
    "#     dict_writer.writerows(toCSV)\n",
    "\n",
    "# import pandas\n",
    "# dataframe = pandas.read_csv(\"exported_spreadsheet.csv\")\n",
    "# list_of_dictionaries = dataframe.to_dict(ros_found_in_billing[1])\n",
    "# dataframe.to_csv(\"exported_spreadsheet.csv\")\n",
    "\n",
    "# with open ('list.csv', 'w') as f:\n",
    "#     for dict in ros_found_in_billing[1]:\n",
    "#         for key, value in dict.items():\n",
    "#             text = key+','+value+'\\n'\n",
    "#             f.writelines(text)\n",
    "\n",
    "# keys = [i for s in [d.keys() for d in ros_found_in_billing[1]] for i in s]\n",
    "\n",
    "# with open('test.csv', 'a') as output_file:\n",
    "#     dict_writer = csv.DictWriter(output_file, restval=\"-\", fieldnames=keys, delimiter='@')\n",
    "#     dict_writer.writeheader()\n",
    "#     dict_writer.writerows(ros_found_in_billing[1])\n",
    "\n",
    "# keys = [i for s in [d.keys() for d in ros_found_in_billing[1]] for i in s]\n",
    "# f = open(\"sample.csv\", \"w\")\n",
    "# writer = csv.DictWriter(\n",
    "#     f, fieldnames=keys)\n",
    "# writer.writeheader()\n",
    "# writer.writerows(ros_found_in_billing[1])\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## next topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
